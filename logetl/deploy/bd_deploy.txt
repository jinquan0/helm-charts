### -------------------------------  prod-bd-xcxsc  -----------------------------------
helm install logetl-prod-bd-xcxsc-admin . --namespace infra --create-namespace \
  --set replicaCount=3 \
  --set etl.Name=logetl-prod-bd-xcxsc-admin \
  --set etl.Kafka.Topic=prod-bd-xcxsc-admin \
  --set etl.Kafka.ConsumerGroup=prod-bd-xcxsc \
  --set-file etl.StreamFilter="./etl/filters/aws-xcxsc-app.conf" \
  --set etl.StreamOutput.elasticsearch.Index=prod-bd-xcxsc-admin-%{+yyyyMM} \
  --set etl.StreamOutput.debugconsole.enabled=false \
  --set etl.StreamOutput.elasticsearch.enabled=true \
  --set etl.StreamOutput.elasticsearch.Pass=B#uU8GMnkjhEygmK

helm install logetl-prod-bd-xcxsc-api . --namespace infra --create-namespace \
  --set replicaCount=3 \
  --set etl.Name=logetl-prod-bd-xcxsc-api \
  --set etl.Kafka.Topic=prod-bd-xcxsc-api \
  --set etl.Kafka.ConsumerGroup=prod-bd-xcxsc \
  --set-file etl.StreamFilter="./etl/filters/aws-xcxsc-app.conf" \
  --set etl.StreamOutput.elasticsearch.Index=prod-bd-xcxsc-api-%{+yyyyMM} \
  --set etl.StreamOutput.debugconsole.enabled=false \
  --set etl.StreamOutput.elasticsearch.enabled=true \
  --set etl.StreamOutput.elasticsearch.Pass=B#uU8GMnkjhEygmK

helm install logetl-prod-bd-xcxsc-messenger . --namespace infra --create-namespace \
  --set replicaCount=3 \
  --set etl.Name=logetl-prod-bd-xcxsc-messenger \
  --set etl.Kafka.Topic=prod-bd-xcxsc-messenger \
  --set etl.Kafka.ConsumerGroup=prod-bd-xcxsc \
  --set-file etl.StreamFilter="./etl/filters/aws-xcxsc-app.conf" \
  --set etl.StreamOutput.elasticsearch.Index=prod-bd-xcxsc-messenger-%{+yyyyMM} \
  --set etl.StreamOutput.debugconsole.enabled=false \
  --set etl.StreamOutput.elasticsearch.enabled=true \
  --set etl.StreamOutput.elasticsearch.Pass=B#uU8GMnkjhEygmK

helm install logetl-prod-bd-xcxsc-cronjob . --namespace infra --create-namespace \
  --set replicaCount=1 \
  --set etl.Name=logetl-prod-bd-xcxsc-cronjob \
  --set etl.Kafka.Topic=prod-bd-xcxsc-cronjob \
  --set etl.Kafka.ConsumerGroup=prod-bd-xcxsc \
  --set-file etl.StreamFilter="./etl/filters/aws-xcxsc-app.conf" \
  --set etl.StreamOutput.elasticsearch.Index=prod-bd-xcxsc-cronjob-%{+yyyyMM} \
  --set etl.StreamOutput.debugconsole.enabled=false \
  --set etl.StreamOutput.elasticsearch.enabled=true \
  --set etl.StreamOutput.elasticsearch.Pass=B#uU8GMnkjhEygmK


helm install logetl-prod-bd-xcxsc-ingngx . --namespace infra --create-namespace \
  --set replicaCount=3 \
  --set image.repository="docker-hub.supor.com/infra/logstash" \
  --set image.tag="7.17.3-geoip" \
  --set etl.Name=logetl-prod-bd-xcxsc-ingngx \
  --set etl.Kafka.Topic=prod-bd-xcxsc-ingngx \
  --set etl.Kafka.ConsumerGroup=prod-bd-xcxsc \
  --set-file etl.StreamFilter="./etl/filters/ingngx-geocity.conf" \
  --set etl.StreamOutput.elasticsearch.Index=logstash-prod-bd-xcxsc-ingngx-%{+yyyyMM} \
  --set etl.StreamOutput.debugconsole.enabled=false \
  --set etl.StreamOutput.elasticsearch.enabled=true \
  --set etl.StreamOutput.elasticsearch.Pass=B#uU8GMnkjhEygmK

## 部署 kafka 消费 etl, input阶段不使用 codec, 日志stream直通到filter
helm install logetl-prod-bd-xcxsc-waflog . --namespace infra --create-namespace \
  --set replicaCount=3 \
  --set image.repository="docker-hub.supor.com/infra/logstash" \
  --set image.tag="7.17.3-geoip" \
  --set etl.Name=logetl-prod-bd-xcxsc-waflog \
  --set etl.Kafka.Topic=prod-bd-xcxsc-waflog \
  --set etl.Kafka.ConsumerGroup=prod-bd-xcxsc \
  --set etl.StreamInput.codecjson.enabled=false \
  --set-file etl.StreamFilter="./etl/filters/awswaf.conf" \
  --set etl.StreamOutput.elasticsearch.Index=logstash-prod-bd-xcxsc-waflog-%{+yyyyMM} \
  --set etl.StreamOutput.debugconsole.enabled=false \
  --set etl.StreamOutput.elasticsearch.enabled=true \
  --set etl.StreamOutput.elasticsearch.Pass=B#uU8GMnkjhEygmK



### logstash etl pipeline 配置检查
/usr/share/logstash/pipeline/stream-input.conf
/usr/share/logstash/pipeline/stream-filter.conf
/usr/share/logstash/pipeline/stream-output.conf


for p in `kubectl get pod -n infra | awk '{print $1}' | grep logetl`
do
  echo "--------------------------- $p -------------------------------"
  kubectl exec -ti pod/$p -n infra -- cat /usr/share/logstash/pipeline/stream-input.conf
  kubectl exec -ti pod/$p -n infra -- cat /usr/share/logstash/pipeline/stream-output.conf
done
